{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958e190e",
   "metadata": {},
   "source": [
    "If you dont have the dataset, run the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b4d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdown.download(\"https://drive.google.com/uc?id=1mW974SwZsSMH-nr89c2Pe9PPHhT1ifDr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a820dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
    "        \n",
    "class StreamingThread(threading.Thread):\n",
    "    def __init__(self, ssc):\n",
    "        super().__init__()\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        self.ssc.start()\n",
    "        self.ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f569d7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.243:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4c5748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.243:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff941f1d810>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f917f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import random\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit, lower\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, SQLTransformer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a0afb",
   "metadata": {},
   "source": [
    "Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068a2c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2156300|    1|136759198|The Demo was grea...|\n",
      "|2372320|    0|136758922|First of, this ga...|\n",
      "|1498040|    1|136761203|Пример того, как ...|\n",
      "|1811990|    1|136761840|I have beaten the...|\n",
      "|1811990|    1|136761635|It really is very...|\n",
      "|1782810|    1|136633021|Great for its cur...|\n",
      "|1649740|    1|136629798|THROW YOUR MONEY ...|\n",
      "|1649740|    1|136629381|I forgot I backed...|\n",
      "|1649740|    1|136628148|Firstly, if you'r...|\n",
      "|1649740|    1|136627883|[h1] HUNT THE NIG...|\n",
      "+-------+-----+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json('/Users/christianbutcher/Desktop/spark/reviews/*')\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf206d1",
   "metadata": {},
   "source": [
    "Clean the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba53e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates(['review_id'])\n",
    "df = df.filter(df['review_text'] != '')\n",
    "df = df.withColumn(\"review_text\", lower(df[\"review_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2dc56",
   "metadata": {},
   "source": [
    "Create a balanced data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39c84b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:============================================>           (20 + 2) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|  499|\n",
      "|    1|  507|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "seed = 1\n",
    "\n",
    "fractions = df.groupBy(\"label\").count().withColumn(\"required_n\", n/col(\"count\"))\\\n",
    "                .drop(\"count\").rdd.collectAsMap()\n",
    "\n",
    "df_bal = df.stat.sampleBy(\"label\", fractions, seed)\n",
    "df_bal.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da02a2e0",
   "metadata": {},
   "source": [
    "Split data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a4228a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 22:==========================>                             (12 + 2) / 25]\r",
      "\r",
      "[Stage 22:============================================>           (20 + 2) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Count: 298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = df_bal.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d27b49e",
   "metadata": {},
   "source": [
    "Inititalise pipeline stages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3944bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"review_text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "# stop words\n",
    "stops = StopWordsRemover.loadDefaultStopWords('english')\n",
    "stopwordsRemover = StopWordsRemover(inputCol=regexTokenizer.getOutputCol(), outputCol=\"filtered\", \n",
    "                                   stopWords = stops)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "\n",
    "\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d5165",
   "metadata": {},
   "source": [
    "Put everything together in the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a0c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14a156dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [10, 100, 1000]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0,0.2,0.5,0.8]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d85b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d94c48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/18 10:41:38 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/05/18 10:41:38 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/18 10:46:27 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "23/05/18 10:46:27 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6398:===================================================>  (24 + 1) / 25]\r"
     ]
    }
   ],
   "source": [
    "# Run cross-validation, and choose the best set of parameters.\n",
    "model = crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "581c6ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RegexTokenizer_67ec11fab942, StopWordsRemover_fcfcb43619a5, HashingTF_f6f2e8ae7c56, IDFModel: uid=IDF_32bdbcb2897f, numDocs=708, numFeatures=1000, LogisticRegressionModel: uid=LogisticRegression_f9c14558cf36, numClasses=2, numFeatures=1000]\n"
     ]
    }
   ],
   "source": [
    "best = model.bestModel\n",
    "print(best.stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b89826e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='HashingTF_f6f2e8ae7c56', name='binary', doc='If True, all non zero counts are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts. Default False.'): False,\n",
       " Param(parent='HashingTF_f6f2e8ae7c56', name='numFeatures', doc='Number of features. Should be greater than 0.'): 1000,\n",
       " Param(parent='HashingTF_f6f2e8ae7c56', name='outputCol', doc='output column name.'): 'rawFeatures',\n",
       " Param(parent='HashingTF_f6f2e8ae7c56', name='inputCol', doc='input column name.'): 'filtered'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.stages[2].extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7b8120b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_f9c14558cf36', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 2,\n",
       " Param(parent='LogisticRegression_f9c14558cf36', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0,\n",
       " Param(parent='LogisticRegression_f9c14558cf36', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial'): 'auto',\n",
       " Param(parent='LogisticRegression_f9c14558cf36', name='featuresCol', doc='features column name.'): 'features',\n",
       " Param(parent='LogisticRegression_f9c14558cf36', name='fitIntercept', doc='whether to fit an intercept term.'): True,\n",
       " Param(parent='LogisticRegression_f9c14558cf36', name='labelCol', doc='label column name.'): 'label',\n",
       " Param(parent='LogisticRegression_f9c14558cf36', name='maxBlockSizeInMB', doc='maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0.'): 0.0,\n",
       " Param(parent='LogisticRegression_f9c14558cf36', name='maxIter', doc='max number of iterations (>= 0).'): 20,\n",
       " Param(parent='LogisticRegression_f9c14558cf36', name='predictionCol', doc='prediction column name.'): 'prediction',\n",
       " Param(parent='LogisticRegression_f9c14558cf36', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability',\n",
       " Param(parent='LogisticRegression_f9c14558cf36', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction',\n",
       " Param(parent='LogisticRegression_f9c14558cf36', name='regParam', doc='regularization parameter (>= 0).'): 0.1,\n",
       " Param(parent='LogisticRegression_f9c14558cf36', name='standardization', doc='whether to standardize the training features before fitting the model.'): True,\n",
       " Param(parent='LogisticRegression_f9c14558cf36', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5,\n",
       " Param(parent='LogisticRegression_f9c14558cf36', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'): 1e-06}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.stages[4].extractParamMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed93839",
   "metadata": {},
   "source": [
    "Obtain predictions for the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcaee192",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6399bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['app_id',\n",
       " 'label',\n",
       " 'review_id',\n",
       " 'review_text',\n",
       " 'words',\n",
       " 'filtered',\n",
       " 'rawFeatures',\n",
       " 'features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04e81b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6399:====================================>                 (17 + 3) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+----------+\n",
      "|         review_text|label|         probability|prediction|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|hai so i dont wit...|    1|[0.29622636001772...|       1.0|\n",
      "|fun game, a worth...|    1|[0.39636672883789...|       1.0|\n",
      "|cute, simple and ...|    1|[0.25049880010621...|       1.0|\n",
      "|wow, where did th...|    1|[0.34961248026696...|       1.0|\n",
      "|this game is just...|    0|[0.68285556407288...|       0.0|\n",
      "|refunded in less ...|    0|[0.97194186498040...|       0.0|\n",
      "|tried it for an h...|    0|[0.74694255342842...|       0.0|\n",
      "|battleblock theat...|    1|[0.23425697935099...|       1.0|\n",
      "|it gets stale ver...|    0|[0.86507549452499...|       0.0|\n",
      "|       oh absolutely|    1|[0.44576065370890...|       1.0|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prediction.select('review_text','label','probability','prediction').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc87cb",
   "metadata": {},
   "source": [
    "Evaluate the model predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7fc0e1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7652802893309227"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b1353cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7315436241610739"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = prediction.filter(prediction.label == prediction.prediction).count() / float(testData.count())\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdafdc7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
