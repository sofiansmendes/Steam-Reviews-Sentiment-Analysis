{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c970b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
    "        \n",
    "class StreamingThread(threading.Thread):\n",
    "    def __init__(self, ssc):\n",
    "        super().__init__()\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        self.ssc.start()\n",
    "        self.ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d5df57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.239:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05430dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.239:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f977826c310>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f3ab6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ebb5f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2156300|    1|136759198|The Demo was grea...|\n",
      "|2372320|    0|136758922|First of, this ga...|\n",
      "|1498040|    1|136761203|Пример того, как ...|\n",
      "|1811990|    1|136761840|I have beaten the...|\n",
      "|1811990|    1|136761635|It really is very...|\n",
      "|1782810|    1|136633021|Great for its cur...|\n",
      "|1649740|    1|136629798|THROW YOUR MONEY ...|\n",
      "|1649740|    1|136629381|I forgot I backed...|\n",
      "|1649740|    1|136628148|Firstly, if you'r...|\n",
      "|1649740|    1|136627883|[h1] HUNT THE NIG...|\n",
      "|1798010|    1|136814124|Out of all the “b...|\n",
      "|2273470|    1|136811469|After just doing ...|\n",
      "|2273470|    1|136810289|Well developed de...|\n",
      "|2329130|    1|136812852|Another title pub...|\n",
      "|2329130|    1|136810307|Rewind or Die is ...|\n",
      "|1928420|    0|137490805|No option to chan...|\n",
      "| 986130|    1|137493446|Awesome game! For...|\n",
      "| 986130|    1|137493372|This is a decent ...|\n",
      "| 986130|    1|137493342|This game is amaz...|\n",
      "| 986130|    1|137492723|Just like space s...|\n",
      "+-------+-----+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json('/Users/christianbutcher/Desktop/spark/reviews/*')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba29c480",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4a58ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates(['review_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a744c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df['review_text'] != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542715a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.select(['review_text','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151fd27f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d5ae80",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43baf826",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=====================================================>  (24 + 1) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|  499|\n",
      "|    1|  507|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Create a balanced data set\n",
    "n = 500\n",
    "seed = 1\n",
    "\n",
    "fractions = df.groupBy(\"label\").count().withColumn(\"required_n\", n/col(\"count\"))\\\n",
    "                .drop(\"count\").rdd.collectAsMap()\n",
    "\n",
    "df_bal = df.stat.sampleBy(\"label\", fractions, seed)\n",
    "df_bal.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f2d14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 22:========================================>               (18 + 1) / 25]\r",
      "\r",
      "[Stage 22:=====================================================>  (24 + 1) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Count: 298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Split data into training and test sets\n",
    "(trainingData, testData) = df_bal.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b1343",
   "metadata": {},
   "source": [
    "# Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70d2dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"review_text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "# stop words\n",
    "stops = StopWordsRemover.loadDefaultStopWords('english')\n",
    "stopwordsRemover = StopWordsRemover(inputCol=regexTokenizer.getOutputCol(), outputCol=\"filtered\", \n",
    "                                   stopWords = stops)\n",
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=stopwordsRemover.getOutputCol(), outputCol=\"features\", \n",
    "                               vocabSize=30000, minDF=5)\n",
    "\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7bb961",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c15a92a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(trainingData)\n",
    "prediction = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4739cb49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|         review_text|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|hai so i dont wit...|    1|[-0.4733160037383...|[0.38383169089462...|       1.0|\n",
      "|Fun game, a worth...|    1|[-0.5438055216783...|[0.36730276583699...|       1.0|\n",
      "|Cute, simple and ...|    1|[-0.8808018891340...|[0.29301163533991...|       1.0|\n",
      "|Wow, where did th...|    1|[0.50605823199372...|[0.62388197841504...|       0.0|\n",
      "|This game is just...|    0|[-0.2981013542337...|[0.42602168839814...|       1.0|\n",
      "|Refunded in less ...|    0|[3.00531139019601...|[0.95281350171842...|       0.0|\n",
      "|Tried it for an h...|    0|[1.56729156828224...|[0.82739715706425...|       0.0|\n",
      "|BattleBlock Theat...|    1|[-0.7038035291780...|[0.33096947657906...|       1.0|\n",
      "|It gets stale ver...|    0|[0.67798488463021...|[0.66328879623877...|       0.0|\n",
      "|       Oh absolutely|    1|[-0.1751339085738...|[0.45632809082043...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select('review_text','label','rawPrediction','probability','prediction').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fe4fb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['app_id',\n",
       " 'label',\n",
       " 'review_id',\n",
       " 'review_text',\n",
       " 'words',\n",
       " 'filtered',\n",
       " 'rawFeatures',\n",
       " 'features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca34d4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7504104984853837"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0611fa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model.write().overwrite().save('/Users/christianbutcher/Desktop/spark/model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295a1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
