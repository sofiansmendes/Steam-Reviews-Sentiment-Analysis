{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958e190e",
   "metadata": {},
   "source": [
    "If you dont have the dataset, run the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b4d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdown.download(\"https://drive.google.com/uc?id=1mW974SwZsSMH-nr89c2Pe9PPHhT1ifDr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a820dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
    "        \n",
    "class StreamingThread(threading.Thread):\n",
    "    def __init__(self, ssc):\n",
    "        super().__init__()\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        self.ssc.start()\n",
    "        self.ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f569d7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.243:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4c5748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.243:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc5a86a5810>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f917f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import random\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit, lower\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, SQLTransformer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a0afb",
   "metadata": {},
   "source": [
    "Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068a2c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2156300|    1|136759198|The Demo was grea...|\n",
      "|2372320|    0|136758922|First of, this ga...|\n",
      "|1498040|    1|136761203|Пример того, как ...|\n",
      "|1811990|    1|136761840|I have beaten the...|\n",
      "|1811990|    1|136761635|It really is very...|\n",
      "|1782810|    1|136633021|Great for its cur...|\n",
      "|1649740|    1|136629798|THROW YOUR MONEY ...|\n",
      "|1649740|    1|136629381|I forgot I backed...|\n",
      "|1649740|    1|136628148|Firstly, if you'r...|\n",
      "|1649740|    1|136627883|[h1] HUNT THE NIG...|\n",
      "+-------+-----+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json('/Users/christianbutcher/Desktop/spark/reviews/*')\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf206d1",
   "metadata": {},
   "source": [
    "Clean the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba53e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates(['review_id'])\n",
    "df = df.filter(df['review_text'] != '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2dc56",
   "metadata": {},
   "source": [
    "Create a balanced data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39c84b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:========================================================(25 + 0) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|  499|\n",
      "|    1|  507|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "seed = 1\n",
    "\n",
    "fractions = df.groupBy(\"label\").count().withColumn(\"required_n\", n/col(\"count\"))\\\n",
    "                .drop(\"count\").rdd.collectAsMap()\n",
    "\n",
    "df_bal = df.stat.sampleBy(\"label\", fractions, seed)\n",
    "df_bal.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da02a2e0",
   "metadata": {},
   "source": [
    "Split data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a4228a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:=================================================>      (22 + 2) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Count: 298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = df_bal.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d27b49e",
   "metadata": {},
   "source": [
    "Inititalise pipeline stages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3944bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"review_text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "# stop words\n",
    "stops = StopWordsRemover.loadDefaultStopWords('english')\n",
    "stopwordsRemover = StopWordsRemover(inputCol=regexTokenizer.getOutputCol(), outputCol=\"filtered\", \n",
    "                                   stopWords = stops)\n",
    "\n",
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=stopwordsRemover.getOutputCol(), outputCol=\"rawFeatures\", \n",
    "                               vocabSize=30000, minDF=5)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "\n",
    "\n",
    "nb = NaiveBayes(smoothing=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d5165",
   "metadata": {},
   "source": [
    "Put everything together in the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a0c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, idf, nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14a156dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(nb.smoothing, [1.0,0.5,0]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d85b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d94c48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Run cross-validation, and choose the best set of parameters.\n",
    "model = crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "581c6ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RegexTokenizer_da41665598fd, StopWordsRemover_29b8a7ae3a45, CountVectorizerModel: uid=CountVectorizer_ce3274ccca16, vocabularySize=1265, IDFModel: uid=IDF_66f504c7689b, numDocs=708, numFeatures=1265, NaiveBayesModel: uid=NaiveBayes_f76681724789, modelType=multinomial, numClasses=2, numFeatures=1265]\n"
     ]
    }
   ],
   "source": [
    "best = model.bestModel\n",
    "print(best.stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed93839",
   "metadata": {},
   "source": [
    "Obtain predictions for the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcaee192",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6399bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['app_id',\n",
       " 'label',\n",
       " 'review_id',\n",
       " 'review_text',\n",
       " 'words',\n",
       " 'filtered',\n",
       " 'rawFeatures',\n",
       " 'features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04e81b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 306:=======================================================(25 + 0) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+----------+\n",
      "|         review_text|label|         probability|prediction|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|hai so i dont wit...|    1|[0.16930921247935...|       1.0|\n",
      "|Fun game, a worth...|    1|           [0.0,1.0]|       1.0|\n",
      "|Cute, simple and ...|    1|[4.80382565299217...|       1.0|\n",
      "|Wow, where did th...|    1|[0.99994094877458...|       0.0|\n",
      "|This game is just...|    0|[0.99542692816129...|       0.0|\n",
      "|Refunded in less ...|    0|           [1.0,0.0]|       0.0|\n",
      "|Tried it for an h...|    0|           [1.0,0.0]|       0.0|\n",
      "|BattleBlock Theat...|    1|           [0.0,1.0]|       1.0|\n",
      "|It gets stale ver...|    0|           [1.0,0.0]|       0.0|\n",
      "|       Oh absolutely|    1|[0.39675528325361...|       1.0|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prediction.select('review_text','label','probability','prediction').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc87cb",
   "metadata": {},
   "source": [
    "Evaluate the model predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7fc0e1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7026672694394214"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852f504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
