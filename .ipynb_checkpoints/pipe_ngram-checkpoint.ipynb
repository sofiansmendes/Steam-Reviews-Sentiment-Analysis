{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958e190e",
   "metadata": {},
   "source": [
    "If you dont have the dataset, run the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b4d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdown.download(\"https://drive.google.com/uc?id=1mW974SwZsSMH-nr89c2Pe9PPHhT1ifDr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a820dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
    "        \n",
    "class StreamingThread(threading.Thread):\n",
    "    def __init__(self, ssc):\n",
    "        super().__init__()\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        self.ssc.start()\n",
    "        self.ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4c5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f917f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import random\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit, lower\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, SQLTransformer, NGram\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a0afb",
   "metadata": {},
   "source": [
    "Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json('/Users/christianbutcher/Desktop/spark/reviews/*')\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00700e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9161db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df['review_text'] == '').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a385b375",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('review_id').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf206d1",
   "metadata": {},
   "source": [
    "Clean the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates(['review_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910467d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df['review_text'] != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45609684",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f778e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2dc56",
   "metadata": {},
   "source": [
    "Create a balanced data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c84b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "seed = 1\n",
    "\n",
    "fractions = df.groupBy(\"label\").count().withColumn(\"required_n\", n/col(\"count\"))\\\n",
    "                .drop(\"count\").rdd.collectAsMap()\n",
    "\n",
    "df_bal = df.stat.sampleBy(\"label\", fractions, seed)\n",
    "df_bal.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da02a2e0",
   "metadata": {},
   "source": [
    "Split data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17235d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = df_bal.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d27b49e",
   "metadata": {},
   "source": [
    "Inititalise pipeline stages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3944bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"review_text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "# stop words\n",
    "stops = StopWordsRemover.loadDefaultStopWords('english')\n",
    "stopwordsRemover = StopWordsRemover(inputCol=regexTokenizer.getOutputCol(), outputCol=\"filtered\", \n",
    "                                   stopWords = stops)\n",
    "\n",
    "ng = NGram(inputCol=stopwordsRemover.getOutputCol(), n=2)\n",
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=ng.getOutputCol(), outputCol=\"rawFeatures\", \n",
    "                               vocabSize=30000, minDF=5)\n",
    "\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "\n",
    "\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d5165",
   "metadata": {},
   "source": [
    "Put everything together in the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a0c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, idf, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a156dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0,0.2,0.5,0.8]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d94c48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run cross-validation, and choose the best set of parameters.\n",
    "model = crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = model.bestModel\n",
    "print(best.stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed93839",
   "metadata": {},
   "source": [
    "Obtain predictions for the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaee192",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6399bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e81b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.select('review_text','label','probability','prediction').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc87cb",
   "metadata": {},
   "source": [
    "Evaluate the model predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc16d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3022296",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator2 = BinaryClassificationEvaluator()\n",
    "evaluator2.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b3618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prediction.select([\"prediction\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fd54bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator3 = BinaryClassificationEvaluator(rawPredictionCol='prediction')\n",
    "evaluator3.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd86021",
   "metadata": {},
   "source": [
    "Save the model locally to access later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961ab5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save('/Users/christianbutcher/Desktop/spark/model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852f504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
